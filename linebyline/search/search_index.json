{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to linebyline About linebyline is a public python package for conducting high-precision radial velocity (RV) analysis, using the \"line-by-line\" technique of Dumusque (2018) and Siegel et al. 2022. This package is a complete RV analysis pipeline, with the ability to process a series of 1D spectra and return corresponding line-by-line radial velocity measurements and stellar activity indices. Currently, HARPS, HARPS-N, NEID, and MAROON-X are supported instruments. Installation To install, download the package, change directories into the downloaded folder, and run: pip install . Authors Siegel, J, Rubenzahl, R, Halverson, S, Howard, A","title":"Home"},{"location":"#welcome-to-linebyline","text":"","title":"Welcome to linebyline"},{"location":"#about","text":"linebyline is a public python package for conducting high-precision radial velocity (RV) analysis, using the \"line-by-line\" technique of Dumusque (2018) and Siegel et al. 2022. This package is a complete RV analysis pipeline, with the ability to process a series of 1D spectra and return corresponding line-by-line radial velocity measurements and stellar activity indices. Currently, HARPS, HARPS-N, NEID, and MAROON-X are supported instruments.","title":"About"},{"location":"#installation","text":"To install, download the package, change directories into the downloaded folder, and run: pip install .","title":"Installation"},{"location":"#authors","text":"Siegel, J, Rubenzahl, R, Halverson, S, Howard, A","title":"Authors"},{"location":"config/","text":"Configuration file This page introduces the configuration file. This file contains all the input parameters for processing stellar spectra using linebyline . The default setting are defined in: linebyline/configs/extraction_config.ini Users can specify alternative input parameters by either changing the above file or providing linebyline with a path to a different configuration file. Below, we outline each parameter in the configuration file (divided between the Instrument and Specbatch objects), as well as the default values. Instrument Object airmass_lim = 1.5 # float, sets the maximum allowed airmass for the # input spectra (e.g., all spectra with a higher airmass are not processed) snr10_lim = 10 # float, sets the minimum SNR for the 10th order verbose = False # bool, sets whether to provide printout statements Specbatch.filter_for_continuum omin = 20 # int, minimum order index (inclusive) considered for filtering omax = 20 # int, maximum order index (inclusive) considered for filtering sigma = 5 # float, number of standard deviations away from the mean # a slope must be in order to be rejected verbose = False # bool, sets whether to provide printout statements Specbatch.normalize_spectral_orders window_size = 100 # int, size of the window for the rolling maximum continuum function # in units of 0.1 A (e.g., size = 100 gives a 10 A wide window) Specbatch.fetch_template template = auto # str, sets the method of deriving the line list; auto yields # native line identification (using local minimums and maximums # in the reference spectrum), otherwise this is treated as the path # to a premade template sampling_per_order = 10000 # int, number of points to evaluate the reference spectrum on # for a given order; the points are uniformly separated. bis_sampling = 100 # int, number of points to evaluate the BIS for each identified line min_width = 10 # int, minimum allowed spectral line width (in pixels) min_depth = 0.05 # float, minimum allowed spectral line depth Specbatch.flag_telluric_TAPAS buffer = 48 # int, a line is rejected if it is within this many # pixels of a telluric feature threshold = 0.99 # float, threshold for identifying telluric contamination # in the TAPAS spectrum (if a feature has a normalized depth # below the threshold it is considered telluric contamination) verbose = False # bool, sets whether to provide printout statements drop = False # bool, sets whether to remove telluric contaminated # lines for the line list filter_window = 100000 # int, width of the window for continuum normalizing the TAPAS # spectrum (this depends on the density of the input TAPAS model) Specbatch.flag_crossover multiple = 512 # int, the separation (in pixels) between CCF stitchings buffer = 48 # int, a line is rejected if it is within this many # pixels of a stitching verbose = True # bool, sets whether to provide printout statements Specbatch.fetch_LBL [fetch_LBL] nproc = 1 # int, number of processors to use width = auto # str or int, if auto the width of a line is determined # natively (based on the nearest local maximas); if an # integer is passed, that value is the adopted line with # in units of pixels interp = False # bool, if True the line depth in inferred via cubic spline # interpolation, otherwise the minimum pixel flux is used verbose = False # bool, sets whether to provide printout statements sampling_per_line = 100 # int, the number of points evaluated if interp = True Specbatch.filter_LBL sigma_rv = 4 sigma_rv_err = 4 sigma_depth = 4 sigma_depth_err = 4 # float, number of standard deviations away from the mean # a RV, RV uncertainty, depth, or depth uncertainty must # be in order to be rejected niter_rv = 4 niter_rv_err = 4 niter_depth = 4 niter_depth_err = 4 # int, number of iterations for the sigma-clipping rejection_fraction = 0.9 # float, if less than fraction of measurements are maintained # for a given line, all measurements for that line are rejected drop = False # bool, sets whether to remove filtered lines for the line list Specbatch[save_functions] npoints = pixel # str or int, density of points to save for the reference spectrum; # if npoints = pixel, the pixel values are used; if npoints an # integer, that number of points is used save_master_name = master.csv save_lbl_data_name = LBL_data.csv save_template_name = template.csv # str, to save the data to","title":"Configuration file"},{"location":"config/#configuration-file","text":"This page introduces the configuration file. This file contains all the input parameters for processing stellar spectra using linebyline . The default setting are defined in: linebyline/configs/extraction_config.ini Users can specify alternative input parameters by either changing the above file or providing linebyline with a path to a different configuration file. Below, we outline each parameter in the configuration file (divided between the Instrument and Specbatch objects), as well as the default values.","title":"Configuration file"},{"location":"config/#instrument-object","text":"airmass_lim = 1.5 # float, sets the maximum allowed airmass for the # input spectra (e.g., all spectra with a higher airmass are not processed) snr10_lim = 10 # float, sets the minimum SNR for the 10th order verbose = False # bool, sets whether to provide printout statements","title":"Instrument Object"},{"location":"config/#specbatchfilter_for_continuum","text":"omin = 20 # int, minimum order index (inclusive) considered for filtering omax = 20 # int, maximum order index (inclusive) considered for filtering sigma = 5 # float, number of standard deviations away from the mean # a slope must be in order to be rejected verbose = False # bool, sets whether to provide printout statements","title":"Specbatch.filter_for_continuum"},{"location":"config/#specbatchnormalize_spectral_orders","text":"window_size = 100 # int, size of the window for the rolling maximum continuum function # in units of 0.1 A (e.g., size = 100 gives a 10 A wide window)","title":"Specbatch.normalize_spectral_orders"},{"location":"config/#specbatchfetch_template","text":"template = auto # str, sets the method of deriving the line list; auto yields # native line identification (using local minimums and maximums # in the reference spectrum), otherwise this is treated as the path # to a premade template sampling_per_order = 10000 # int, number of points to evaluate the reference spectrum on # for a given order; the points are uniformly separated. bis_sampling = 100 # int, number of points to evaluate the BIS for each identified line min_width = 10 # int, minimum allowed spectral line width (in pixels) min_depth = 0.05 # float, minimum allowed spectral line depth","title":"Specbatch.fetch_template"},{"location":"config/#specbatchflag_telluric_tapas","text":"buffer = 48 # int, a line is rejected if it is within this many # pixels of a telluric feature threshold = 0.99 # float, threshold for identifying telluric contamination # in the TAPAS spectrum (if a feature has a normalized depth # below the threshold it is considered telluric contamination) verbose = False # bool, sets whether to provide printout statements drop = False # bool, sets whether to remove telluric contaminated # lines for the line list filter_window = 100000 # int, width of the window for continuum normalizing the TAPAS # spectrum (this depends on the density of the input TAPAS model)","title":"Specbatch.flag_telluric_TAPAS"},{"location":"config/#specbatchflag_crossover","text":"multiple = 512 # int, the separation (in pixels) between CCF stitchings buffer = 48 # int, a line is rejected if it is within this many # pixels of a stitching verbose = True # bool, sets whether to provide printout statements","title":"Specbatch.flag_crossover"},{"location":"config/#specbatchfetch_lbl","text":"[fetch_LBL] nproc = 1 # int, number of processors to use width = auto # str or int, if auto the width of a line is determined # natively (based on the nearest local maximas); if an # integer is passed, that value is the adopted line with # in units of pixels interp = False # bool, if True the line depth in inferred via cubic spline # interpolation, otherwise the minimum pixel flux is used verbose = False # bool, sets whether to provide printout statements sampling_per_line = 100 # int, the number of points evaluated if interp = True","title":"Specbatch.fetch_LBL"},{"location":"config/#specbatchfilter_lbl","text":"sigma_rv = 4 sigma_rv_err = 4 sigma_depth = 4 sigma_depth_err = 4 # float, number of standard deviations away from the mean # a RV, RV uncertainty, depth, or depth uncertainty must # be in order to be rejected niter_rv = 4 niter_rv_err = 4 niter_depth = 4 niter_depth_err = 4 # int, number of iterations for the sigma-clipping rejection_fraction = 0.9 # float, if less than fraction of measurements are maintained # for a given line, all measurements for that line are rejected drop = False # bool, sets whether to remove filtered lines for the line list","title":"Specbatch.filter_LBL"},{"location":"config/#specbatchsave_functions","text":"npoints = pixel # str or int, density of points to save for the reference spectrum; # if npoints = pixel, the pixel values are used; if npoints an # integer, that number of points is used save_master_name = master.csv save_lbl_data_name = LBL_data.csv save_template_name = template.csv # str, to save the data to","title":"Specbatch[save_functions]"},{"location":"pipeline/","text":"Tutorials Here we walk through the linebyline pipeline and highlight available features. A Jupyter notebook version of this tutorial is available at: linebyline/docs/tutorials/ For more details on each step and what parameters the user can change, see the configuration file page. Step 0: Imports and the configuration file We first must navigate to the following directory: linebyline/docs/tutorials For this tutorial, the following imports are necessary. import os from linebyline.instruments import instrument from linebyline.specbatch import SpecBatch from linebyline.configs import config from linebyline.parse import ParseSpec To specify the default parameters for the pipeline, we also need to define a configuration file (see the configuration file page for details on the different parameters): cfg = config.get_config('../../linebyline/configs/extraction_config.ini') Step 1: Correcting for known systematics In this first step, the user provides a list of paths to stellar spectra and specifies the corresponding instrument; depending on the instrument, the user may also need to provide paths to the blaze correction files and the cross-correlation function (CCF) files. Given these user inputs, linebyline will load in the provided spectra and correct each for known systematics, including blaze corrections and Doppler shifting the wavelength solution into the heliocentric frame. In this step, we also specify filters on airmass and activity level (see the configuration file page for details on the available filters). Below we outline this step for each supported instrument. HARPS Once in the , we first gather the stellar spectra: ps = os.listdir('../example_data/HARPS/alphaCenB/spectra') paths = ['../example_data/HARPS/alphaCenB/spectra/' + p for p in ps] We then build two dictionaries that point to each spectra's corresponding blaze and CCF file: blaze_key = {} for p in paths: blaze_key[p] = '../example_data/HARPS/alphaCenB/blaze/' + fits.open(p)[0].header['HIERARCH ESO DRS BLAZE FILE'] ccf_key = {} for p in paths: ccf_key[p] = '../example_data/HARPS/alphaCenB/ccf/' + p.split('/')[-1].replace('_e2ds_A','_ccf_K5_A') Lastly, we must initialize the instrument object with these paths and dictionaries, obs = instrument.HARPS(paths, blaze_key, cfg, ccf_key) The instrument object obs can now be passed to the next step in the pipeline and will facilitate loading in the stellar spectra and correcting for known systematics. MAROON-X For MAROON-X, we initialize the instrument object as, obs = instrument.MAROONX(paths, blaze_key, cfg) Notice, ccf_key is no longer required. Step 2: Line-by-line measurements Next, we implement the line-by-line technique outlined by Dumusque (2018) . Note, for here on, the pipeline is agnostic to the chosen instrument (the instrument object we defined in Step 1 will handle all instrument specific concerns). To begin, we define the SpecBatch object, batch = SpecBatch( obs, target = target, config = cfg ) where obs and cfg were defined above, and target is a string that will be the name of the directory for saving the results. We must then load all the input stellar spectra, batch.load_spectra() and normalize their continuums (using a rolling maximum), batch.normalize_spectral_orders() a. Filtering the spectra Before proceeding further, we must remove outlier observations from the input stellar spectra. linebyline filters observations based on the slope of each spectral orders continuum, batch.filter_for_continuum() The user can specify additional filters, by controlling the list of paths passed to linebyline . b. Building a reference spectrum Next, we build a reference spectrum form the input stellar spectra. batch.create_master() To help with memory usage, next call batch.flush() to remove the loaded spectra from active memory (we don't need to have them all loaded at once now that we have the reference spectrum). c. Generating (or importing) a catalog of spectral lines To conduct the line-by-line measurements, we need a catalog of spectral lines. This catalog can either be generated based on the reference spectrum or imported from a user specified file. To specify a list of spectral lines, set the template parameter for batch.fetch_template to a path to the line list. User defined line lists must have the same format as the ESPRESSO line lists. Examples for the K5 and G2 stellar types are provided in, linebyline/docs/example_data/synthetic_templates For example, to use the ESPRESSO K5 template, batch.fetch_template(template='../example_data/synthetic_templates/K5.mas') Alternatively, to have the catalog generated from the reference spectrum, set template='auto' and call, batch.fetch_template(template='auto') Regardless of whether the line list is generated from the reference spectra or user specified, we next want to flag potentially contaminated lines, including those near tellurics or near stichings in the CCD: batch.flag_telluric_TAPAS('../example_data/TAPAS/TAPAS_WMKO_NORAYLEIGH_SPEC') batch.flag_crossover() where we have pointed to an example TAPAS atmospheric spectrum for batch.flag_telluric_TAPAS . d. Making the measurements We're now ready to conduct the line-by-line measurements (yay!). This is handled by the following call, batch.fetch_LBL() To help reduce run-times, the user can specify the number of processors to use. e. Filtering Lastly, we flag outlier line-by-line measurements, batch.filter_LBL() f. Saving To save our results, we run, batch.save_template() batch.save_LBL_data() batch.save_master() Step 3: Processing the measurements Now that we have made the line-by-line measurements, what can we do with them? To start, we load the saved results into the ParseSpec object. dat = ParseSpec(target + '/') where target is the same specified in Step 2. The line-by-line measurements are stored as pandas.DataFrame in dat.data . We next reject flagged measurements (including lines contaminated by tellurics or rejected by the sigma clipping in Step 2f), dat.enforce_filter() To calculate the bulk RV for each spectra, we run t,rv,er = dat.fetch_bulk_RVs(log=True) where log=True saves the bulk RVs to dat.data .","title":"Tutorials"},{"location":"pipeline/#tutorials","text":"Here we walk through the linebyline pipeline and highlight available features. A Jupyter notebook version of this tutorial is available at: linebyline/docs/tutorials/ For more details on each step and what parameters the user can change, see the configuration file page.","title":"Tutorials"},{"location":"pipeline/#step-0-imports-and-the-configuration-file","text":"We first must navigate to the following directory: linebyline/docs/tutorials For this tutorial, the following imports are necessary. import os from linebyline.instruments import instrument from linebyline.specbatch import SpecBatch from linebyline.configs import config from linebyline.parse import ParseSpec To specify the default parameters for the pipeline, we also need to define a configuration file (see the configuration file page for details on the different parameters): cfg = config.get_config('../../linebyline/configs/extraction_config.ini')","title":"Step 0: Imports and the configuration file"},{"location":"pipeline/#step-1-correcting-for-known-systematics","text":"In this first step, the user provides a list of paths to stellar spectra and specifies the corresponding instrument; depending on the instrument, the user may also need to provide paths to the blaze correction files and the cross-correlation function (CCF) files. Given these user inputs, linebyline will load in the provided spectra and correct each for known systematics, including blaze corrections and Doppler shifting the wavelength solution into the heliocentric frame. In this step, we also specify filters on airmass and activity level (see the configuration file page for details on the available filters). Below we outline this step for each supported instrument.","title":"Step 1: Correcting for known systematics"},{"location":"pipeline/#harps","text":"Once in the , we first gather the stellar spectra: ps = os.listdir('../example_data/HARPS/alphaCenB/spectra') paths = ['../example_data/HARPS/alphaCenB/spectra/' + p for p in ps] We then build two dictionaries that point to each spectra's corresponding blaze and CCF file: blaze_key = {} for p in paths: blaze_key[p] = '../example_data/HARPS/alphaCenB/blaze/' + fits.open(p)[0].header['HIERARCH ESO DRS BLAZE FILE'] ccf_key = {} for p in paths: ccf_key[p] = '../example_data/HARPS/alphaCenB/ccf/' + p.split('/')[-1].replace('_e2ds_A','_ccf_K5_A') Lastly, we must initialize the instrument object with these paths and dictionaries, obs = instrument.HARPS(paths, blaze_key, cfg, ccf_key) The instrument object obs can now be passed to the next step in the pipeline and will facilitate loading in the stellar spectra and correcting for known systematics.","title":"HARPS"},{"location":"pipeline/#maroon-x","text":"For MAROON-X, we initialize the instrument object as, obs = instrument.MAROONX(paths, blaze_key, cfg) Notice, ccf_key is no longer required.","title":"MAROON-X"},{"location":"pipeline/#step-2-line-by-line-measurements","text":"Next, we implement the line-by-line technique outlined by Dumusque (2018) . Note, for here on, the pipeline is agnostic to the chosen instrument (the instrument object we defined in Step 1 will handle all instrument specific concerns). To begin, we define the SpecBatch object, batch = SpecBatch( obs, target = target, config = cfg ) where obs and cfg were defined above, and target is a string that will be the name of the directory for saving the results. We must then load all the input stellar spectra, batch.load_spectra() and normalize their continuums (using a rolling maximum), batch.normalize_spectral_orders()","title":"Step 2: Line-by-line measurements"},{"location":"pipeline/#a-filtering-the-spectra","text":"Before proceeding further, we must remove outlier observations from the input stellar spectra. linebyline filters observations based on the slope of each spectral orders continuum, batch.filter_for_continuum() The user can specify additional filters, by controlling the list of paths passed to linebyline .","title":"a. Filtering the spectra"},{"location":"pipeline/#b-building-a-reference-spectrum","text":"Next, we build a reference spectrum form the input stellar spectra. batch.create_master() To help with memory usage, next call batch.flush() to remove the loaded spectra from active memory (we don't need to have them all loaded at once now that we have the reference spectrum).","title":"b. Building a reference spectrum"},{"location":"pipeline/#c-generating-or-importing-a-catalog-of-spectral-lines","text":"To conduct the line-by-line measurements, we need a catalog of spectral lines. This catalog can either be generated based on the reference spectrum or imported from a user specified file. To specify a list of spectral lines, set the template parameter for batch.fetch_template to a path to the line list. User defined line lists must have the same format as the ESPRESSO line lists. Examples for the K5 and G2 stellar types are provided in, linebyline/docs/example_data/synthetic_templates For example, to use the ESPRESSO K5 template, batch.fetch_template(template='../example_data/synthetic_templates/K5.mas') Alternatively, to have the catalog generated from the reference spectrum, set template='auto' and call, batch.fetch_template(template='auto') Regardless of whether the line list is generated from the reference spectra or user specified, we next want to flag potentially contaminated lines, including those near tellurics or near stichings in the CCD: batch.flag_telluric_TAPAS('../example_data/TAPAS/TAPAS_WMKO_NORAYLEIGH_SPEC') batch.flag_crossover() where we have pointed to an example TAPAS atmospheric spectrum for batch.flag_telluric_TAPAS .","title":"c. Generating (or importing) a catalog of spectral lines"},{"location":"pipeline/#d-making-the-measurements","text":"We're now ready to conduct the line-by-line measurements (yay!). This is handled by the following call, batch.fetch_LBL() To help reduce run-times, the user can specify the number of processors to use.","title":"d. Making the measurements"},{"location":"pipeline/#e-filtering","text":"Lastly, we flag outlier line-by-line measurements, batch.filter_LBL()","title":"e. Filtering"},{"location":"pipeline/#f-saving","text":"To save our results, we run, batch.save_template() batch.save_LBL_data() batch.save_master()","title":"f. Saving"},{"location":"pipeline/#step-3-processing-the-measurements","text":"Now that we have made the line-by-line measurements, what can we do with them? To start, we load the saved results into the ParseSpec object. dat = ParseSpec(target + '/') where target is the same specified in Step 2. The line-by-line measurements are stored as pandas.DataFrame in dat.data . We next reject flagged measurements (including lines contaminated by tellurics or rejected by the sigma clipping in Step 2f), dat.enforce_filter() To calculate the bulk RV for each spectra, we run t,rv,er = dat.fetch_bulk_RVs(log=True) where log=True saves the bulk RVs to dat.data .","title":"Step 3: Processing the measurements"}]}